{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f69c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bandwidth=estimate_bandwidth(X,quantile=0.2,n_samples=500)\n",
    "ms=MeanShift(bandwidth=bandwidth,bin_seeding=True)\n",
    "ms.fit(X)\n",
    "segmented_image=ms.labels_\n",
    "segmented_image.shape=image.shape\n",
    "imshow(segmented_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89380172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift,estimate_bandwidth\n",
    "def images_segmentation(train_path=train_set_path, test_path=test_set_path):\n",
    "\n",
    "    print('-- REGION-BASED SEGMENTATION --')\n",
    "    \n",
    "    # Python dictionaries containing the properties of the regions representing\n",
    "    # the lesions (subdivided into training and test set)\n",
    "    segmented_train_set = {}\n",
    "    segmented_test_set = {}\n",
    "    \n",
    "    if not os.path.isdir(train_path):\n",
    "        train_path = train_set_path\n",
    "    # get absolute path of the training set\n",
    "    abs_train_path = os.path.abspath(train_path)\n",
    "\n",
    "    if not os.path.isdir(test_path):\n",
    "        test_path = test_set_path\n",
    "    # get absolute path of the test set\n",
    "    abs_test_path = os.path.abspath(test_path)\n",
    "\n",
    "    # list of images in the training set\n",
    "    train_imgs = [img_file for img_file in os.listdir(abs_train_path)\n",
    "                  if os.path.isfile(os.path.join(abs_train_path, img_file)) and img_file.endswith('.jpg')]\n",
    "    # list of images in the test set\n",
    "    test_imgs = [img_file for img_file in os.listdir(abs_test_path)\n",
    "                 if os.path.isfile(os.path.join(abs_test_path, img_file)) and img_file.endswith('.jpg')]\n",
    "\n",
    "    img_list = train_imgs + test_imgs\n",
    "\n",
    "    for idx, image_name in enumerate(img_list):\n",
    "        if idx < plot_limit:\n",
    "            print('{:_<100}'.format(''))\n",
    "            print('Image name: {}'.format(image_name))\n",
    "\n",
    "        # get image path\n",
    "        if image_name in train_imgs:\n",
    "            image_path = os.path.join(abs_train_path, image_name)\n",
    "        elif image_name in test_imgs:\n",
    "            image_path = os.path.join(abs_test_path, image_name)\n",
    "        else:\n",
    "            print('Error: Cannot find {}'.format(image_name))\n",
    "            return None, None\n",
    "        # read image\n",
    "        image = io.imread(image_path)\n",
    "        # convert the original image into grayscale\n",
    "        gray_img = color.rgb2gray(image)\n",
    "\n",
    "        # 1] Apply Sobel filter\n",
    "        elevation_map = filters.sobel(gray_img)\n",
    "\n",
    "        # 2] Build image markers using the threshold obtained through the ISODATA filter\n",
    "        markers = np.zeros_like(gray_img)\n",
    "        threshold = filters.threshold_isodata(gray_img)\n",
    "        markers[gray_img > threshold] = 1\n",
    "        markers[gray_img < threshold] = 2\n",
    "        \n",
    "        # 3] Apply Wathershed algorithm in order to segment the image filtered\n",
    "        #    using the markers\n",
    "        \n",
    "        bandwidth=estimate_bandwidth(elevation_map,quantile=0.2,n_samples=500)\n",
    "        ms=MeanShift(bandwidth=bandwidth,bin_seeding=True)\n",
    "        ms.fit(elevation_map)\n",
    "        segmented_image=ms.labels_\n",
    "        segmented_image.shape=image.shape\n",
    "        imshow(segmented_image)\n",
    "        # 4] Improve segmantation:\n",
    "        #    >  Fill small holes \n",
    "        segmented_img = ndi.binary_fill_holes(segmented_img - 1)\n",
    "        #    > Remove small objects that have an area less than 800 px:\n",
    "        #      this could be useful to exclude some regions that does not represent a lesion\n",
    "        segmented_img = morphology.remove_small_objects(segmented_img, min_size=800)\n",
    "        #    > Clear regions connected to the image borders.\n",
    "        #      This operation is very useful when there are contour regions have a\n",
    "        #      big area and so they can be exchanged with the lesion.\n",
    "        #      However, this can also create some issues when the lesion region is\n",
    "        #      connected to the image borders. In order to (try to) overcome this\n",
    "        #      issue, we use a lesion identification algorithm (see below)\n",
    "        img_border_cleared = segmentation.clear_border(segmented_img)\n",
    "\n",
    "        # 5] Apply connected components labeling algorithm:\n",
    "        #    it assigns labels to a pixel such that adjacent pixels of the same\n",
    "        #    features are assigned the same label.\n",
    "        # labeled_img, _ = ndi.label(segmented_img)\n",
    "        labeled_img = morphology.label(img_border_cleared)\n",
    "\n",
    "        if idx < plot_limit:\n",
    "            # create a subplot of 3 figures in order to show elevation map,\n",
    "            # markers and the segmanted image\n",
    "            fig, ax = plt.subplots(1, 3, figsize=(10, 8))\n",
    "            ax[0].imshow(elevation_map, cmap=plt.cm.gray)\n",
    "            ax[0].set_title('elevation map')\n",
    "            ax[0].set_axis_off()\n",
    "\n",
    "            ax[1].imshow(markers, cmap=plt.cm.nipy_spectral)\n",
    "            ax[1].set_title('markers')\n",
    "            ax[1].set_axis_off()\n",
    "\n",
    "            ax[2].imshow(segmented_img, cmap=plt.cm.gray)\n",
    "            ax[2].set_title('segmentation')\n",
    "            ax[2].set_axis_off()\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show();\n",
    "        \n",
    "        # 6] Lesion identification algorithm:\n",
    "        # Compute properties of labeled image regions:\n",
    "        # it will be used to automatically select the region that contains\n",
    "        # the skin lesion according to area and extent\n",
    "        props = measure.regionprops(labeled_img)\n",
    "        # num labels -> num regions\n",
    "        num_labels = len(props)\n",
    "        # Get all the area of detected regions\n",
    "        areas = [region.area for region in props]\n",
    "\n",
    "        # If we have at least one region and the area of the region having the\n",
    "        # biggest area is at least 1200 px, we choose it as the region that\n",
    "        # contains the leson because if properly segmented (i.e., after removing\n",
    "        # small objects and regions on the image contours (since in most of the\n",
    "        # images, the lesion is in the center))\n",
    "        if num_labels > 0 and areas[np.argmax(areas)] >= 1200:\n",
    "            if idx < plot_limit:\n",
    "                print('Num labels:', num_labels)\n",
    "                print('Areas: {}'.format(areas))\n",
    "            target_label = props[np.argmax(areas)].label\n",
    "        else:\n",
    "            # ... otherwise we could have one of the following two cases:\n",
    "            # 1] num_labels == 0:\n",
    "            #    this can happen when there is only one region (the one containing the lesion)\n",
    "            #    but it has been deleted when applying the function segmentation.clear_border()\n",
    "            # 2] num_labels > 0 but areas[np.argmax(areas)] < 1200:\n",
    "            #    it means that there exists at least one region but all the regions have\n",
    "            #    an area less than 1200 pixels.\n",
    "            #    This can happen when the region containing the lesion is deleted\n",
    "            #    with segmentation.clear_border() but there still other regions that\n",
    "            #    could be \"exhanged for\" a lesion region\n",
    "            #\n",
    "            # Since both cases can be due to the deletion of the segmented area\n",
    "            # because of the use of segmentation.clear_border(), the idea is to\n",
    "            # backtrack to the original segmented image (the one obtained \n",
    "            # obtained before applying segmentation.clear_border()), apply again the\n",
    "            # connected components labeling algorithm and extract the new region properties.\n",
    "            # In addition, in order to find the region representing the lesion,\n",
    "            # we use area and extent features by checking among the three largest regions\n",
    "            # (if any because there could be only one or two regions) sorted in ascending order\n",
    "            # (i.e. from the one having the largest area) the first that has an extent grater than 0.5.\n",
    "            labeled_img = morphology.label(segmented_img)\n",
    "            # Get new region properties\n",
    "            props = measure.regionprops(labeled_img)\n",
    "            # Get the new list of areas\n",
    "            areas = [region.area for region in props]\n",
    "            # List of regions' extent.\n",
    "            # Each extent is defined as the ratio of pixels in the region  to pixels\n",
    "            # in the total bounding box (computed as: area / (rows * cols))\n",
    "            extents = [region.extent for region in props]\n",
    "            if idx < plot_limit:\n",
    "                print('Num labels: {}'.format(len(props)))\n",
    "                print('Areas: {}'.format(areas))\n",
    "                print('Extents: {}'.format(extents))\n",
    "            # Get the index of the region having the largest area and if there are\n",
    "            # more than one or two regions, find also the index of the second and\n",
    "            # third most largest regions.\n",
    "            region_max1 = np.argmax(areas)\n",
    "            if len(props) > 1:\n",
    "                areas_copy = areas.copy()\n",
    "                areas_copy[region_max1] = 0\n",
    "                region_max2 = np.argmax(areas_copy)\n",
    "            if len(props) > 2:\n",
    "                areas_copy[region_max2] = 0\n",
    "                region_max3 = np.argmax(areas_copy)\n",
    "\n",
    "            # If the largest region has an extent greater than 0.50, it is our target region\n",
    "            if extents[region_max1] > 0.50:\n",
    "                target_label = props[region_max1].label\n",
    "            # ... else check if the extent of the second largest region is greater than 0.5,\n",
    "            # and if so we have found our target region\n",
    "            elif len(props) > 1 and extents[region_max2] > 0.50:\n",
    "                target_label = props[region_max2].label\n",
    "            # ... else if the third largest region has an extent greater than 0.50,\n",
    "            # it is (more probably) the one containing the lesion\n",
    "            elif len(props) > 2 and extents[region_max3] > 0.50:\n",
    "                target_label = props[region_max3].label\n",
    "            # ... otherwise we choose the largest region\n",
    "            else:\n",
    "                target_label = props[region_max1].label\n",
    "\n",
    "            # NOTE: another possible approarch could be to select as the target region\n",
    "            #       the one having the largest extent among the 3 largest regions found:\n",
    "            # if len(props) > 2:\n",
    "            #     extents_largest_reg = [val if idx in (region_max1, region_max2, region_max3) else 0.0\n",
    "            #                            for idx, val in enumerate(extents)]\n",
    "            # elif len(props) > 1:\n",
    "            #     extents_largest_reg = [val if idx in (region_max1, region_max2) else 0.0\n",
    "            #                            for idx, val in enumerate(extents)]\n",
    "            # else:\n",
    "            #     extents_largest_reg = [val if idx in (region_max1,) else 0.0\n",
    "            #                            for idx, val in enumerate(extents)]\n",
    "            # target_label = props[np.argmax(extents_largest_reg)].label\n",
    "\n",
    "        # assign label 0 to all the pixels that are not in the target region (that is\n",
    "        # the ragion that more probably contains the lesion)\n",
    "        for row, col in np.ndindex(labeled_img.shape):\n",
    "            if labeled_img[row, col] != target_label:\n",
    "                labeled_img[row, col] = 0\n",
    "        # Convert the labeled image into its RGB version\n",
    "        image_label_overlay = color.label2rgb(labeled_img, gray_img)\n",
    "\n",
    "        if idx < plot_limit:\n",
    "            print('Chosen label: {}'.format(target_label))\n",
    "            # Plot the original image ('image') in which the contours of all the\n",
    "            # segmented regions are highlighted\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(8, 6), sharey=True)\n",
    "            axes[0].imshow(image)\n",
    "            axes[0].contour(segmented_img, [0.5], linewidths=1.2, colors='y')\n",
    "            axes[0].axis('off')\n",
    "            # Plot 'image_label_overlay' that contains the target region highlighted\n",
    "            axes[1].imshow(image_label_overlay)\n",
    "            axes[1].axis('off')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show();\n",
    "        elif idx == plot_limit:\n",
    "            print('Continuing segmentation without printing the results ...')\n",
    "\n",
    "        # Add the the found region into the proper dictionary according to whether\n",
    "        # the current image belongs to the training or the test set\n",
    "        if image_name in train_imgs:\n",
    "            segmented_train_set[image_name] = props[target_label - 1]\n",
    "        elif image_name in test_imgs:\n",
    "            segmented_test_set[image_name] = props[target_label - 1]\n",
    "\n",
    "    return segmented_train_set, segmented_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91fa55c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 450 into shape (450,600,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m ms\u001b[38;5;241m.\u001b[39mfit(elevation_map)\n\u001b[0;32m     20\u001b[0m segmented_image\u001b[38;5;241m=\u001b[39mms\u001b[38;5;241m.\u001b[39mlabels_\n\u001b[1;32m---> 21\u001b[0m \u001b[43msegmented_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[38;5;241m=\u001b[39mimage\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     22\u001b[0m imshow(segmented_image)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# 4] Improve segmantation:\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m#    >  Fill small holes \u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 450 into shape (450,600,3)"
     ]
    }
   ],
   "source": [
    "        image = io.imread(\"dataset/ISIC_0024306.jpg\")\n",
    "        # convert the original image into grayscale\n",
    "        gray_img = color.rgb2gray(image)\n",
    "\n",
    "        # 1] Apply Sobel filter\n",
    "        elevation_map = filters.sobel(gray_img)\n",
    "\n",
    "        # 2] Build image markers using the threshold obtained through the ISODATA filter\n",
    "        markers = np.zeros_like(gray_img)\n",
    "        threshold = filters.threshold_isodata(gray_img)\n",
    "        markers[gray_img > threshold] = 1\n",
    "        markers[gray_img < threshold] = 2\n",
    "        \n",
    "        # 3] Apply Wathershed algorithm in order to segment the image filtered\n",
    "        #    using the markers\n",
    "        X=elevation_map.reshape((-1,1))\n",
    "        bandwidth=estimate_bandwidth(X,quantile=0.2,n_samples=500)\n",
    "        ms=MeanShift(bandwidth=bandwidth,bin_seeding=True)\n",
    "        ms.fit(elevation_map)\n",
    "        segmented_image=ms.labels_\n",
    "        segmented_image.shape=image.shape\n",
    "        imshow(segmented_image)\n",
    "        # 4] Improve segmantation:\n",
    "        #    >  Fill small holes \n",
    "        segmented_img = ndi.binary_fill_holes(segmented_img - 1)\n",
    "        #    > Remove small objects that have an area less than 800 px:\n",
    "        #      this could be useful to exclude some regions that does not represent a lesion\n",
    "        segmented_img = morphology.remove_small_objects(segmented_img, min_size=800)\n",
    "        #    > Clear regions connected to the image borders.\n",
    "        #      This operation is very useful when there are contour regions have a\n",
    "        #      big area and so they can be exchanged with the lesion.\n",
    "        #      However, this can also create some issues when the lesion region is\n",
    "        #      connected to the image borders. In order to (try to) overcome this\n",
    "        #      issue, we use a lesion identification algorithm (see below)\n",
    "        img_border_cleared = segmentation.clear_border(segmented_img)\n",
    "\n",
    "        # 5] Apply connected components labeling algorithm:\n",
    "        #    it assigns labels to a pixel such that adjacent pixels of the same\n",
    "        #    features are assigned the same label.\n",
    "        # labeled_img, _ = ndi.label(segmented_img)\n",
    "        labeled_img = morphology.label(img_border_cleared)\n",
    "\n",
    "        if idx < plot_limit:\n",
    "            # create a subplot of 3 figures in order to show elevation map,\n",
    "            # markers and the segmanted image\n",
    "            fig, ax = plt.subplots(1, 3, figsize=(10, 8))\n",
    "            ax[0].imshow(elevation_map, cmap=plt.cm.gray)\n",
    "            ax[0].set_title('elevation map')\n",
    "            ax[0].set_axis_off()\n",
    "\n",
    "            ax[1].imshow(markers, cmap=plt.cm.nipy_spectral)\n",
    "            ax[1].set_title('markers')\n",
    "            ax[1].set_axis_off()\n",
    "\n",
    "            ax[2].imshow(segmented_img, cmap=plt.cm.gray)\n",
    "            ax[2].set_title('segmentation')\n",
    "            ax[2].set_axis_off()\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show();\n",
    "        \n",
    "        # 6] Lesion identification algorithm:\n",
    "        # Compute properties of labeled image regions:\n",
    "        # it will be used to automatically select the region that contains\n",
    "        # the skin lesion according to area and extent\n",
    "        props = measure.regionprops(labeled_img)\n",
    "        # num labels -> num regions\n",
    "        num_labels = len(props)\n",
    "        # Get all the area of detected regions\n",
    "        areas = [region.area for region in props]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef6185c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "from sklearn.cluster import MeanShift,estimate_bandwidth\n",
    "# %matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, \\\n",
    "                            recall_score, accuracy_score, classification_report\n",
    "\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from skimage import io, exposure, morphology, filters, color, \\\n",
    "                    segmentation, feature, measure, img_as_float, img_as_ubyte\n",
    "from skimage.color.adapt_rgb import adapt_rgb, each_channel, hsv_value\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, \\\n",
    "                         Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af78e934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72c3427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createColorHistogram(img, binCount = 256, out = plt):\n",
    "   \n",
    "    img=(img.astype(float))/255.0\n",
    "    img_hsv = colors.rgb_to_hsv(img[…,:3])\n",
    "    img_hsv=img_hsv[…,0].flatten()\n",
    "    return out.hist(img_hsv*360,binCount,range=(0.0,binCount), label=’Hue’)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660f8b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prob_distr(img, histogram, min_saturation, min_value, min_prob):\n",
    "    (h_values,bin_edges,n) = histogram\n",
    "    h_values = min_max_scaling(h_values)\n",
    "    img = (img.astype(float))/255.0\n",
    "    img_hsv = colors.rgb_to_hsv(img[…,:3])\n",
    "    prob_distr = np.zeros((img_hsv.shape[0], img_hsv.shape[1]))\n",
    "    for i in range(img_hsv.shape[0]):\n",
    "        for j in range(img_hsv.shape[1]):\n",
    "        \n",
    "            bin_index = np.digitize(img_hsv[i][j][0]*360,bin_edges, right=True)\n",
    "            if(img_hsv[i][j][1] < min_saturation or img_hsv[i][j][2] < min_value or h_values[bin_index-1] < min_prob):\n",
    "                prob_distr[i][j] = 0.0\n",
    "            else:\n",
    "                prob_distr[i][j] = h_values[bin_index-1]\n",
    "    return prob_distr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d457179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
